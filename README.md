
# 🌐 Wikipedia Scraper

## 🚀 Introduction

This tool allows you to extract content from Wikipedia articles in any language directly from your command line.

## 🛠️ Features
- 🌍 Supports all Wikipedia languages

- 🔍 Extracts main content from articles

- 💻 Easy-to-use command-line interface

- ⚡ Fast and efficient scraping

- 🐞 Built-in error handling

## 🔧 Installation

Before you start, make sure you have Node.js installed on your machine. Then follow these steps:

- Clone this repository:

```bash
git clone https://github.com/queaxtra/wikipedia-scraper.git
```

- Navigate to the project directory:

```bash
cd wikipedia-scraper
```

- Install the dependencies:

```bash
bun install
```

## 🚀 Usage

To use the Wikipedia Scraper, follow these steps:

- Run the scraper:

```bash
bun run index.ts
```

- When prompted, enter the Wikipedia article title you want to scrape.

- Next, enter the language code for the Wikipedia version you want to scrape (e.g., 'en' for English, 'es' for Spanish, 'ja' for Japanese).

- Sit back and watch as the content is scraped and displayed in your terminal! 🎉

## 📷 Screenshot

![Screenshot](https://www.upload.ee/image/16835255/SCR-20240707-qquc.png)

## 🧰 Technologies Used

- TypeScript: For type-safe JavaScript coding

- Axios: For making HTTP requests

- Cheerio: For parsing HTML and extracting data

- Readline: For handling user input in the command line

## 🤝 Contributing

Contributions are always welcome! Here's how you can help:

- 🍴 Fork the repository

- 🔧 Make your changes

- 📥 Submit a pull request

Please make sure to update tests as appropriate and adhere to the code style of the project.

## 📜 License

This project is licensed under the MIT License - see the LICENSE.md file for details.

## 🙏 Acknowledgements

- Thanks to Wikipedia for providing a wealth of information

- Shout out to the open-source community for the amazing tools and libraries