
# ğŸŒ Wikipedia Scraper

## ğŸš€ Introduction

This tool allows you to extract content from Wikipedia articles in any language directly from your command line.

## ğŸ› ï¸ Features
- ğŸŒ Supports all Wikipedia languages

- ğŸ” Extracts main content from articles

- ğŸ’» Easy-to-use command-line interface

- âš¡ Fast and efficient scraping

- ğŸ Built-in error handling

## ğŸ”§ Installation

Before you start, make sure you have Node.js installed on your machine. Then follow these steps:

- Clone this repository:

```bash
git clone https://github.com/queaxtra/wikipedia-scraper.git
```

- Navigate to the project directory:

```bash
cd wikipedia-scraper
```

- Install the dependencies:

```bash
bun install
```

## ğŸš€ Usage

To use the Wikipedia Scraper, follow these steps:

- Run the scraper:

```bash
bun run index.ts
```

- When prompted, enter the Wikipedia article title you want to scrape.

- Next, enter the language code for the Wikipedia version you want to scrape (e.g., 'en' for English, 'es' for Spanish, 'ja' for Japanese).

- Sit back and watch as the content is scraped and displayed in your terminal! ğŸ‰

## ğŸ“· Screenshot

![Screenshot](https://www.upload.ee/image/16835255/SCR-20240707-qquc.png)

## ğŸ§° Technologies Used

- TypeScript: For type-safe JavaScript coding

- Axios: For making HTTP requests

- Cheerio: For parsing HTML and extracting data

- Readline: For handling user input in the command line

## ğŸ¤ Contributing

Contributions are always welcome! Here's how you can help:

- ğŸ´ Fork the repository

- ğŸ”§ Make your changes

- ğŸ“¥ Submit a pull request

Please make sure to update tests as appropriate and adhere to the code style of the project.

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE.md file for details.

## ğŸ™ Acknowledgements

- Thanks to Wikipedia for providing a wealth of information

- Shout out to the open-source community for the amazing tools and libraries